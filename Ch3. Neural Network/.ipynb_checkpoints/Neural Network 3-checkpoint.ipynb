{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输出函数设计\n",
    "### softmax\n",
    "恒等函数：恒等函数会将输入按原样输出，对于输入的信息，不加以任何改动地直接输出。\n",
    "![](../img/identity.png)\n",
    "softmax函数：\n",
    "$$\n",
    "    y_k = \\frac{\\exp(a_k)}{\\sum^n_{i=1}\\exp(a_i)}\n",
    "$$\n",
    "第k个神经元的输出是$y_k$，n表示n个输出神经元。分母是输入，即上层输出a_k；分母是该层所有神经元的输入和。\n",
    "![](../img/softmax.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0460998 , 0.02796094, 0.92593926])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(a):\n",
    "    exp_a = np.exp(a) # 对a中每个元素求e的指数\n",
    "    sum_exp_a = np.sum(exp_a) # 计算a的指数和\n",
    "    return exp_a/sum_exp_a\n",
    "\n",
    "a = np.array([1.0, 0.5, 4.0])\n",
    "softmax(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax的改进\n",
    "上面的softmax函数的实现虽然正确描述了式，但在计算机的运算上有一定的缺陷。这个缺陷就是溢出问题。softmax函数的实现中要进行指数函数的运算，但是此时指数函数的值很容易变得非常大。所以一般用以下方式改进softmax函数：\n",
    "$$\n",
    "    y_k = \\frac{C\\exp(a_k)}{C\\sum^n_{i=1}\\exp(a_i)}\n",
    "    =\\frac{ \\exp(a_k)}{C\\sum^n_{i=1}\\exp(a_i)}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
