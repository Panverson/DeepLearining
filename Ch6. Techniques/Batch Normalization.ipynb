{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Normalization\n",
    "#### 优点\n",
    "- 可以使学习快速进行（可以增大学习率）。\n",
    "- 不那么依赖初始值（对于初始值不用那么神经质）。\n",
    "- 抑制过拟合（降低Dropout等的必要性）。\n",
    "\n",
    "\n",
    "#### 原理\n",
    "Batch Norm的思路是调整各层的激活值分布使其拥有适当的广度。要向神经网络中插入对数据分布进行正规化的层，即Batch\n",
    "Normalization 层。\n",
    "![image.png](../img/norm.png)\n",
    "使数据分布的均值为0、方差为1。\n",
    "$$\n",
    "\\mu_B \\gets \\frac{1}{m}\\sum_{i=1}^{m}x_i  \\\\\n",
    "\\sigma^2_B \\gets \\frac{1}{m}\\sum_{i=1}^m(x_i-\\mu_B)^2 \\\\\n",
    "\\hat{x}_i \\gets \\frac{x_i-\\mu_B}{\\sqrt{\\sigma^2_B+\\varepsilon}}\n",
    "$$\n",
    "接着，Batch Norm层会对正规化后的数据进行缩放和平移的变换:\n",
    "$$\n",
    "y_i\\gets\\gamma\\hat{x}_i+\\beta\n",
    "$$\n",
    "$γ$和$β$是参数。一开始$γ = 1$，$β = 0$，然后再通过学习调整到合适的值."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过拟合\n",
    "发生过拟合的原因，主要有以下两个。\n",
    "- 模型拥有大量参数、表现力强。\n",
    "- 训练数据少。\n",
    "\n",
    "#### 权值衰减\n",
    "权值衰减是一直以来经常被使用的一种抑制过拟合的方法。该方法通过在学习的过程中对大的权重进行惩罚，来抑制过拟合。很多过拟合原本就是因为权重参数取值过大才发生的。\n",
    "为损失函数加上权重的平方范数（L2 范数）。这样一来，就可以抑制权重变大：\n",
    "$$\n",
    "\\frac{1}{2}\\lambda\\pmb{W}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
